{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading and writing data with Pandas\n",
    "\n",
    "We have seen some of the basic things we can do with Pandas. In doing so, we created some simple DataFrames from dicts. That was simple, but it is almost never how we create DataFrames in the wild. \n",
    "\n",
    "Most data live in files, often as comma-sparated values or as MS Excel workbooks, either on our computers or in the cloud. In this notebook, we will review was to get data into (and out of) Pandas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from your computer\n",
    "\n",
    "Let's start by getting files from our own computers. We start by loading Pandas. We are also loading the os package. `os` means 'operating system' and it contains functions that help us navigate the file structure of our computers.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd     # load the pandas package and call it pd\n",
    "import os               # The package name is already short enough. No need to rename it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have not already, move the `gdp_components.csv` file to your U:\\ drive and put it in the same folder that holds this notebook. We expect this file to contain U.S. GDP and its major components. Let's see.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = pd.read_csv('gdp_components.csv')       # read_csv is a part of Pandas, so we need the pd. \n",
    "print(type(gdp))                              # What have we got here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks successful. `read_csv()` takes a string with the file name and creates a DataFrame. Let's take a look at the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though jupyter notebook hid rows 30-58, this is still a bit obnoxious. We can use the `head()` and `tail()` methods of DataFrame to peek at just the first or last few rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( gdp.head(4) )            # Show the first 4 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you do not pass `head()` or `tail()` an argument, it defaults to 5 rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( gdp.tail() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index isn't very sensible. This is time series data (the unit of observation is a year), so the date seems like a good index. How do we set the index?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_new_index = gdp.set_index('DATE')   # We could use 'inplace = True' if we didn't need a copy.\n",
    "\n",
    "print(gdp_new_index.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also set the index as we read in the file. Let's take a look at the read_csv() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm seeing a lot of good stuff here. `index_col`, `usecols`, `header`, `sep`,...some stuff I don't know about, too. When reading in messy files, these extra arguments may come in handy. \n",
    "\n",
    "Let's give `index_col` a try. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_2 = pd.read_csv('gdp_components.csv', index_col = 0)    # Treat the CSV like a DataFrame. Count cols staring with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigating your file structure\n",
    "We dumped our file into our **current working directory** so we could just ask for the file name `gdp_components.csv` in `read_csv()`. What is our current working directory (cwd)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_cwd = os.getcwd()           # getcwd() is part of the os package we imported earlier\n",
    "print(path_to_cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we gave read_csv() gpd_components.csv, it looked in our cwd for the file. Let's try something more complicated. Go into your Data_Class folder and create a new folder called Data_Files. Make a copy of the gdp_components file and paste it into the Data_Files folder. Rename the file `gdp_components_moved.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_moved = pd.read_csv('gdp_components_moved.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course this doesn't work. The file is not in our cwd. It's good see what that kind of error message looks like. We need to pass csv_read() the *path* to the file. The path is the hierarchy of folders that contains the file. In my case, the path is \n",
    "\n",
    "U:\\Data_Class\\Data_Files\n",
    "\n",
    "Note that there is a  `\\` each time we list a new folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_moved = pd.read_csv('U:\\Data_Class\\Data_Files\\gdp_components_moved.csv')\n",
    "gdp_moved.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could have manipulated some strings to get to this, too. This approach might be useful if you needed to read in many files from the same place. (Maybe using a for loop and a list of file names?) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_cwd = os.getcwd()\n",
    "file_name = 'gdp_components_moved.csv'\n",
    "path_to_data_file = path_to_cwd + '\\\\Data_Files\\\\' +  file_name  #Note the double \\ characters\n",
    "print(path_to_data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp_moved = pd.read_csv(path_to_data_file, index_col=0)\n",
    "gdp_moved.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice: Reading CSVs\n",
    "Take a few minutes and try the following. Feel free to chat with those around if you get stuck. The TA and I are here, too.\n",
    "\n",
    "1. Try out the `to_csv()` method of DataFrame. Save `gdp_moved` as 'gdp_moved_2.csv' in your cwd. \\[You can use `?` if you need help.\\]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Use `to_csv()` again to save `gdp_moved` to the Data_Files folder. Name it 'gdp_moved_3.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are your files in the correct places? \n",
    "\n",
    "Isn't this supposed to be practice reading in CSV files? Right. Let's do some of that. \n",
    "\n",
    "3. Use gdp_moved_3.csv to create a DataFrame named gdp_growth. Set the index to the dates. Print out the first 10 years of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Rename 'GDPA' to 'gdp' and rename 'GCEA' to 'gov'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Excel spreadsheets\n",
    "Reading spreadsheets isn't much different than reading csv files. But, since workbooks are more complicated than csv files, we have a few more options to consider. \n",
    "\n",
    "If you haven't already, copy over debt.xlsx to your cwd. Let's open it in Excel and have a look at it...\n",
    "\n",
    "There's a lot going on here: missing data, some #N/A stuff, and several header rows. Let's get to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debt = pd.read_excel('debt.xlsx')\n",
    "debt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the header to specify the row to use as the column names. (zero based, as usual)\n",
    "\n",
    "debt = pd.read_excel('debt.xlsx', header = 12)\n",
    "\n",
    "print(debt.head())\n",
    "print('\\n')\n",
    "print(debt.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's looking good. Notice that Pandas added NaN for the missing data and for those #N\\A entries. We will have to deal with those at some point. The header parameter is part of `read_csv()`, too.\n",
    "\n",
    "We didn't specify which sheet in the workbook to load, so Pandas took the first one. We can ask for sheets by name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "debt_q = pd.read_excel('debt.xlsx', header=12, sheet_name='quarterly')\n",
    "print(debt_q.head())\n",
    "print('\\n')\n",
    "print(debt_q.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can ask for just a subset of the columns when reading in a file (csv or xlsx). Use the `usecols` argument. This takes either integers or Excel column letters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the first and third columns of sheet 'quarterly'\n",
    "\n",
    "interest_rates = pd.read_excel('debt.xlsx', header=12,  sheet_name='quarterly', usecols=[0,2])  \n",
    "interest_rates.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice: Reading Excel\n",
    "Take a few minutes and try the following. Feel free to chat with those around if you get stuck. The TA and I are here, too.\n",
    "\n",
    "1. Read in the quarterly data from 'debt.xlsx' and keep only the columns with the date, gdp, and GFDEBTN. Name your new DataFrame `fed_debt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Oops, I wanted to set the observation_date to the index. Go back and add that to your solution to 1. \n",
    "3. What is 'GFDEBTN'? It is the federal debt, in millions. Rename this variable to 'DEBT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Create a variable name debt_ratio that is the debt to GDP ratio. Debt is in millions and gdp is in billions. Adjust accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of missing debt values. Did Pandas throw an error? No. Pandas knows (in some cases) how to work around missing data. \n",
    "5. Summarize the debt_ratio variable. What is its max level? Its min?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from the internet\n",
    "We can pass `read` functions urls, too. We will see a different way to read data from internet sites set up with APIs. Soon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the penn world table data\n",
    "url = \"http://www.rug.nl/ggdc/docs/pwt81.xlsx\"\n",
    "pwt = pd.read_excel(url, sheet_name= \"Data\")\n",
    "pwt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That took a few seconds --- this is a pretty big file. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data from McKinney's book. Each file contains baby name counts for a year. \n",
    "baby_url = 'https://raw.githubusercontent.com/wesm/pydata-book/2nd-edition/datasets/babynames'\n",
    "\n",
    "# What was trendy in 1880?\n",
    "old_names = pd.read_csv(baby_url + '//yob1880.txt')\n",
    "old_names.head()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've lost Mary, which looks pretty popular. What happened? \n",
    "\n",
    "We can specify no header with the `None` keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_names = pd.read_csv(baby_url + '//yob1880.txt', header=None)\n",
    "old_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practice\n",
    "Take a few minutes and try the following. Feel free to chat with those around if you get stuck. The TA and I are here, too.\n",
    "\n",
    "### Baby names\n",
    "\n",
    "1. Get the baby name data for 2009. Call the DataFrame `new_names`. Give the columns some reasonable names.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What are the two most popular female names in 1880?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. What are the two least popular female names in 1880?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pisa Scores\n",
    "\n",
    "1. In a web browser, go to [dx.doi.org/10.1787/888932937035](http://dx.doi.org/10.1787/888932937035) This should initiate a download of an excel file with pisa scores across countries. This is a bit of a mess. Open the file in Excel and take a look. \n",
    "\n",
    "2. Use the `read_url()` function to create a DataFrame with mean scores in math, reading, and science. Do not set an index yet. There is some junk at the bottom of the spreadsheet. Try the `skipfooter` argument. Print out a few rows. How does it look?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Clean up your DataFrame. Drop rows that have NaNs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Make the country names the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. What is the US pisa scores OECD average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Challenging. How correlated are pisa math, reading, and science scores with each other? Write the correlation matrix to a file called 'pisa_corrs.xlsx'\n",
    "\n",
    "This is a challenging question because, depending on how you read in the data, your columns are probably of type 'Object' and corr() won't work. Google around and see if you can convert the three columns to numbers. Then find the correlations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Attachments",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
